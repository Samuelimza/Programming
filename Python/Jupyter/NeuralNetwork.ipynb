{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created by Osama Ashhad Azmi in March '18\n",
    "\n",
    "\"\"\"\n",
    "To Do:\n",
    "# Use np functions to append bias, delete delta\n",
    "# Fix the accuracy function for one hot compatibility\n",
    "# Implement the cost function\n",
    "# If possible clean the train function\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layerN):\n",
    "        self.m = None\n",
    "        self.layerN = layerN\n",
    "        self.w = [2 * np.random.random((layerN[i] + 1, layerN[i + 1])) - 1 for i in range(len(layerN) - 1)]\n",
    "        self.layer = [None for _ in range(len(layerN))]\n",
    "\n",
    "    # function to implement forward propagation\n",
    "    def feedForward(self, X):\n",
    "        self.layer[0] = self.addBias(X)\n",
    "        for i in range(1, len(self.layerN) - 1):\n",
    "            self.layer[i] = self.addBias(self.activate(self.layer[i - 1].dot(self.w[i - 1])))\n",
    "        self.layer[len(self.layerN) - 1] = self.activate(self.layer[len(self.layerN) - 2].dot(self.w[len(self.layerN) - 2]))\n",
    "\n",
    "    # function to implement back propagation\n",
    "    def backProp(self, Y):\n",
    "        delta = [None for _ in range(len(self.layerN))]\n",
    "        delta[len(self.layerN) - 1] = Y - self.layer[len(self.layerN) - 1]\n",
    "        for i in range(len(self.layerN) - 2, 0, -1):\n",
    "            delta[i] = self.removeRedundantDelta((delta[i + 1].dot(self.w[i].T)) * self.activate(self.layer[i], True))\n",
    "        for i in range(len(self.layerN) - 1):\n",
    "            self.w[i] += self.layer[i].T.dot(delta[i + 1]) * (1 / len(Y))\n",
    "\n",
    "    # function to train the NN on passed data\n",
    "    def train(self, X, Y, epochs, batchSize=None):\n",
    "        self.m = len(X)\n",
    "        if batchSize is None:\n",
    "            flag = False\n",
    "        else:\n",
    "            indices = [i for i in range(self.m)]\n",
    "            random.shuffle(indices)\n",
    "            temp = [X[i] for i in indices]\n",
    "            X = temp\n",
    "            temp = [Y[i] for i in indices]\n",
    "            Y = temp\n",
    "            flag = True\n",
    "\n",
    "        for j in range(epochs):\n",
    "            # print('Epoch:', j)\n",
    "            if flag:\n",
    "                i = 0\n",
    "                while i + batchSize < self.m:\n",
    "                    self.feedForward(X[i:i + batchSize])\n",
    "                    self.backProp(Y[i:i + batchSize])\n",
    "                    i += batchSize\n",
    "                self.feedForward(X[i:self.m])\n",
    "                self.backProp(Y[i:self.m])\n",
    "            else:\n",
    "                self.feedForward(X)\n",
    "                self.backProp(Y)\n",
    "\n",
    "    # function to calculate accuracy on passed data\n",
    "    def getAccuracy(self, X, Y):\n",
    "        self.feedForward(X)\n",
    "        output = self.layer[len(self.layerN) - 1]\n",
    "        count = 0\n",
    "        for i in range(len(output)):\n",
    "            maxi = 0\n",
    "            maxIndex = None\n",
    "            for j in range(len(output[i])):\n",
    "                if output[i][j] > maxi:\n",
    "                    maxi = output[i][j]\n",
    "                    maxIndex = j\n",
    "                output[i][j] = 0\n",
    "            if Y[i][maxIndex] == 1:\n",
    "                count += 1\n",
    "            # output[i][maxIndex] = 1\n",
    "        return count / self.m\n",
    "\n",
    "    # activation function (sigmoid) that can also calculate g'(z) when flag is set\n",
    "    @staticmethod\n",
    "    def activate(layer, flag=False):\n",
    "        if flag:\n",
    "            return layer * (1 - layer)\n",
    "        return 1 / (1 + np.exp(-layer))\n",
    "\n",
    "    # function to remove delta corresponding to the bias units during back propagation\n",
    "    @staticmethod\n",
    "    def removeRedundantDelta(delta):\n",
    "        newDelta = np.zeros((len(delta), len(delta[0]) - 1))\n",
    "        for i in range(len(delta)):\n",
    "            newDelta[i] = delta[i][:-1].copy()\n",
    "        return newDelta\n",
    "\n",
    "    # function to add bias units during forward propagation\n",
    "    @staticmethod\n",
    "    def addBias(layer):\n",
    "        newLayer = np.zeros((len(layer), len(layer[0]) + 1))\n",
    "        for i in range(len(layer)):\n",
    "            newLayer[i] = np.append(layer[i], [1])\n",
    "        return newLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training now!\n",
      "Training finished!\n",
      "Time taken:  40.55876803398132 s\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " ..., \n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "[[  9.99915976e-01   8.42264786e-05]\n",
      " [  9.99916850e-01   8.75734649e-05]\n",
      " [  9.99914360e-01   8.99297453e-05]\n",
      " ..., \n",
      " [  7.83407769e-05   9.99880269e-01]\n",
      " [  7.81985955e-05   9.99880468e-01]\n",
      " [  1.01325137e-04   9.99846926e-01]]\n",
      "Accuracy:  100.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2006a1fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from NeuralNetwork import NeuralNetwork\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def printBoundary(nn, xStart, xEnd, yStart, yEnd, xi, yi):\n",
    "    arr = []\n",
    "    x1 = xStart\n",
    "    while x1 <= xEnd:\n",
    "        x2 = yStart\n",
    "        while x2 <= yEnd:\n",
    "            arr.append([x1, x2])\n",
    "            x2 += xi\n",
    "        x1 += yi\n",
    "    nn.feedForward(np.array(arr))\n",
    "    for i in range(len(nn.layer[len(nn.layerN) - 1])):\n",
    "        if nn.layer[3][i][0] > nn.layer[3][i][1]:\n",
    "            plt.plot(nn.layer[0][i][0], nn.layer[0][i][1], 'rs')\n",
    "        else:\n",
    "            plt.plot(nn.layer[0][i][0], nn.layer[0][i][1], 'bs')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data = np.genfromtxt('clusterincluster.txt', delimiter=' ')\n",
    "\n",
    "# input data\n",
    "x = np.array([[data[i][j] for j in range(2)] for i in range(len(data))])  # np.array(data[:,:2])\n",
    "\n",
    "# output data\n",
    "y = np.array([[data[i][2]] for i in range(len(data))])\n",
    "myDict = makeDict(y)\n",
    "yOneHot = convertToOneHot(y, myDict)\n",
    "\n",
    "n = NeuralNetwork([2, 6, 6, 2])\n",
    "print('Training now!')\n",
    "start = time.time()\n",
    "n.train(x, yOneHot, epochs=200, batchSize=100)\n",
    "end = time.time()\n",
    "print('Training finished!')\n",
    "print('Time taken: ', end - start, 's')\n",
    "\n",
    "# print output layer after training\n",
    "n.feedForward(x)\n",
    "# print(n.layer[len(n.layerN) - 1])\n",
    "print('Accuracy: ', n.getAccuracy(x, yOneHot) * 100)\n",
    "printBoundary(n, -6, 6, -6, 6, 0.2, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDict(arr):\n",
    "    myDict = {}\n",
    "    counter = 0\n",
    "    for i in range(len(arr)):\n",
    "        if not arr[i][0] in myDict.values():\n",
    "            myDict[counter] = arr[i][0]\n",
    "            counter += 1\n",
    "    return myDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToOneHot(y, myDict):\n",
    "    oneHot = np.zeros((len(y), len(myDict)))\n",
    "    for i in range(len(y)):\n",
    "        myKey = None\n",
    "        for key, value in myDict.items():\n",
    "            if value == y[i][0]:\n",
    "                myKey = key\n",
    "        oneHot[i][myKey] = 1\n",
    "    return oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [[1],[2],[2],[1],[4],[3],[2],[3],[2],[1]]\n",
    "myDict = makeDict(arr)\n",
    "convertToOneHot(arr, myDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
