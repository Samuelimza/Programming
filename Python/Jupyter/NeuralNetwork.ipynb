{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created by Osama Ashhad Azmi in March '18\n",
    "\n",
    "\"\"\"\n",
    "To Do:\n",
    "# Use np functions to append bias, delete delta\n",
    "# Fix the accuracy function for one hot compatibility\n",
    "# Implement the cost function\n",
    "# If possible clean the train function\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layerN):\n",
    "        self.m = None\n",
    "        self.layerN = layerN\n",
    "        self.w = [2 * np.random.random((layerN[i] + 1, layerN[i + 1])) - 1 for i in range(len(layerN) - 1)]\n",
    "        self.layer = [None for _ in range(len(layerN))]\n",
    "\n",
    "    # function to implement forward propagation\n",
    "    def feedForward(self, X):\n",
    "        self.layer[0] = self.addBias(X)\n",
    "        for i in range(1, len(self.layerN) - 1):\n",
    "            self.layer[i] = self.addBias(self.activate(self.layer[i - 1].dot(self.w[i - 1])))\n",
    "        self.layer[len(self.layerN) - 1] = self.activate(self.layer[len(self.layerN) - 2].dot(self.w[len(self.layerN) - 2]))\n",
    "\n",
    "    # function to implement back propagation\n",
    "    def backProp(self, Y):\n",
    "        delta = [None for _ in range(len(self.layerN))]\n",
    "        delta[len(self.layerN) - 1] = Y - self.layer[len(self.layerN) - 1]\n",
    "        for i in range(len(self.layerN) - 2, 0, -1):\n",
    "            delta[i] = self.removeRedundantDelta((delta[i + 1].dot(self.w[i].T)) * self.activate(self.layer[i], True))\n",
    "        for i in range(len(self.layerN) - 1):\n",
    "            self.w[i] += self.layer[i].T.dot(delta[i + 1]) * (1 / len(Y))\n",
    "\n",
    "    # function to train the NN on passed data\n",
    "    def train(self, X, Y, epochs, batchSize=None):\n",
    "        self.m = len(X)\n",
    "        if batchSize is None:\n",
    "            flag = False\n",
    "        else:\n",
    "            indices = [i for i in range(self.m)]\n",
    "            random.shuffle(indices)\n",
    "            temp = [X[i] for i in indices]\n",
    "            X = temp\n",
    "            temp = [Y[i] for i in indices]\n",
    "            Y = temp\n",
    "            flag = True\n",
    "\n",
    "        for j in range(epochs):\n",
    "            # print('Epoch:', j)\n",
    "            if flag:\n",
    "                i = 0\n",
    "                while i + batchSize < self.m:\n",
    "                    self.feedForward(X[i:i + batchSize])\n",
    "                    self.backProp(Y[i:i + batchSize])\n",
    "                    i += batchSize\n",
    "                self.feedForward(X[i:self.m])\n",
    "                self.backProp(Y[i:self.m])\n",
    "            else:\n",
    "                self.feedForward(X)\n",
    "                self.backProp(Y)\n",
    "\n",
    "    # function to calculate accuracy on passed data\n",
    "    def getAccuracy(self, X, Y):\n",
    "        self.feedForward(X)\n",
    "        output = self.layer[len(self.layerN) - 1]\n",
    "        for i in range(len(output)):\n",
    "            maxi = 0\n",
    "            maxIndex = None\n",
    "            for j in range(len(output[i])):\n",
    "                output[i][j] = 0\n",
    "                if output[i][j] > maxi:\n",
    "                    maxi = output[i][j]\n",
    "                    maxIndex = j\n",
    "            output[i][maxIndex] = 1\n",
    "        return count / self.m\n",
    "\n",
    "    # activation function (sigmoid) that can also calculate g'(z) when flag is set\n",
    "    @staticmethod\n",
    "    def activate(layer, flag=False):\n",
    "        if flag:\n",
    "            return layer * (1 - layer)\n",
    "        return 1 / (1 + np.exp(-layer))\n",
    "\n",
    "    # function to remove delta corresponding to the bias units during back propagation\n",
    "    @staticmethod\n",
    "    def removeRedundantDelta(delta):\n",
    "        newDelta = np.zeros((len(delta), len(delta[0]) - 1))\n",
    "        for i in range(len(delta)):\n",
    "            newDelta[i] = delta[i][:-1].copy()\n",
    "        return newDelta\n",
    "\n",
    "    # function to add bias units during forward propagation\n",
    "    @staticmethod\n",
    "    def addBias(layer):\n",
    "        newLayer = np.zeros((len(layer), len(layer[0]) + 1))\n",
    "        for i in range(len(layer)):\n",
    "            newLayer[i] = np.append(layer[i], [1])\n",
    "        return newLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training now!\n",
      "Training finished!\n",
      "Time taken:  45.52436327934265 s\n",
      "Accuracy:  0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x253db8716d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from NeuralNetwork import NeuralNetwork\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def printBoundary(nn, xStart, xEnd, yStart, yEnd, xi, yi):\n",
    "    arr = []\n",
    "    x1 = xStart\n",
    "    while x1 <= xEnd:\n",
    "        x2 = yStart\n",
    "        while x2 <= yEnd:\n",
    "            arr.append([x1, x2])\n",
    "            x2 += xi\n",
    "        x1 += yi\n",
    "    nn.feedForward(np.array(arr))\n",
    "    for i in range(len(nn.layer[len(nn.layerN) - 1])):\n",
    "        if nn.layer[3][i][0] > nn.layer[3][i][1]:\n",
    "            plt.plot(nn.layer[0][i][0], nn.layer[0][i][1], 'rs')\n",
    "        else:\n",
    "            plt.plot(nn.layer[0][i][0], nn.layer[0][i][1], 'bs')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "data = np.genfromtxt('clusterincluster.txt', delimiter=' ')\n",
    "\n",
    "# input data\n",
    "x = np.array([[data[i][j] for j in range(2)] for i in range(len(data))])  # np.array(data[:,:2])\n",
    "\n",
    "# output data\n",
    "y = np.array([[data[i][2]] for i in range(len(data))])\n",
    "myDict = makeDict(y)\n",
    "yOneHot = convertToOneHot(y, myDict)\n",
    "\n",
    "n = NeuralNetwork([2, 6, 6, 2])\n",
    "print('Training now!')\n",
    "start = time.time()\n",
    "n.train(x, yOneHot, epochs=200, batchSize=100)\n",
    "end = time.time()\n",
    "print('Training finished!')\n",
    "print('Time taken: ', end - start, 's')\n",
    "\n",
    "# print output layer after training\n",
    "n.feedForward(x)\n",
    "# print(n.layer[len(n.layerN) - 1])\n",
    "print('Accuracy: ', n.getAccuracy(x, y) * 100)\n",
    "printBoundary(n, -6, 6, -6, 6, 0.2, 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDict(arr):\n",
    "    myDict = {}\n",
    "    counter = 0\n",
    "    for i in range(len(arr)):\n",
    "        if not arr[i][0] in myDict.values():\n",
    "            myDict[counter] = arr[i][0]\n",
    "            counter += 1\n",
    "    return myDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToOneHot(y, myDict):\n",
    "    oneHot = np.zeros((len(y), len(myDict)))\n",
    "    for i in range(len(y)):\n",
    "        myKey = None\n",
    "        for key, value in myDict.items():\n",
    "            if value == y[i][0]:\n",
    "                myKey = key\n",
    "        oneHot[i][myKey] = 1\n",
    "    return oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [[1],[2],[2],[1],[4],[3],[2],[3],[2],[1]]\n",
    "myDict = makeDict(arr)\n",
    "convertToOneHot(arr, myDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
